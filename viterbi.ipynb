{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Viterbi algorithm example:\n",
    "\n",
    "[Wikipedia says](https://en.wikipedia.org/wiki/Viterbi_algorithm):\n",
    "\n",
    "> The Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states – called the Viterbi path – that results in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models\n",
    "\n",
    "> [...]\n",
    "\n",
    "> It is now also commonly used in speech recognition, speech synthesis, diarization, keyword spotting, computational linguistics, and bioinformatics. For example, in speech-to-text (speech recognition), the acoustic signal is treated as the observed sequence of events, and a string of text is considered to be the \"hidden cause\" of the acoustic signal. The Viterbi algorithm finds the most likely string of text given the acoustic signal.\n",
    "\n",
    "Let's start with a pure Python implementation of the example given on [Wikipedia](https://en.wikipedia.org/wiki/Viterbi_algorithm#Example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01512, ['Healthy', 'Healthy', 'Fever'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = ('Healthy', 'Fever')\n",
    " \n",
    "observations = ('normal', 'cold', 'dizzy')\n",
    " \n",
    "start_probability = {'Healthy': 0.6, 'Fever': 0.4}\n",
    " \n",
    "transition_probability = {\n",
    "   'Healthy' : {'Healthy': 0.7, 'Fever': 0.3},\n",
    "   'Fever' : {'Healthy': 0.4, 'Fever': 0.6}\n",
    "   }\n",
    " \n",
    "emission_probability = {\n",
    "   'Healthy' : {'normal': 0.5, 'cold': 0.4, 'dizzy': 0.1},\n",
    "   'Fever' : {'normal': 0.1, 'cold': 0.3, 'dizzy': 0.6}\n",
    "   }\n",
    "\n",
    "def viterbi(obs, states, start_p, trans_p, emit_p):\n",
    "    V = [{}]\n",
    "    path = {}\n",
    " \n",
    "    # Initialize base cases (t == 0)\n",
    "    for y in states:\n",
    "        V[0][y] = start_p[y] * emit_p[y][obs[0]]\n",
    "        path[y] = [y]\n",
    " \n",
    "    # Run Viterbi for t > 0\n",
    "    for t in range(1, len(obs)):\n",
    "        V.append({})\n",
    "        newpath = {}\n",
    " \n",
    "        for y in states:\n",
    "            (prob, state) = max((V[t-1][y0] * trans_p[y0][y] * emit_p[y][obs[t]], y0) for y0 in states)\n",
    "            V[t][y] = prob\n",
    "            newpath[y] = path[state] + [y]\n",
    " \n",
    "        # Don't need to remember the old paths\n",
    "        path = newpath\n",
    "    n = 0           # if only one element is observed max is sought in the initialization values\n",
    "    if len(obs) != 1:\n",
    "        n = t\n",
    "    # print_dptable(V)\n",
    "    (prob, state) = max((V[n][y], y) for y in states)\n",
    "    return (prob, path[state])\n",
    " \n",
    "# Don't study this, it just prints a table of the steps.\n",
    "def print_dptable(V):\n",
    "    s = \"    \" + \" \".join((\"%7d\" % i) for i in range(len(V))) + \"\\n\"\n",
    "    for y in V[0]:\n",
    "        s += \"%.5s: \" % y\n",
    "        s += \" \".join(\"%.7s\" % (\"%f\" % v[y]) for v in V)\n",
    "        s += \"\\n\"\n",
    "    print(s)\n",
    "\n",
    "viterbi(observations, states, start_probability, transition_probability, emission_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's time this implementation with very short observations (length=3) and long observations (length=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "long_observations = list(observations) * 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 loops, best of 3: 12.3 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit viterbi(observations, states, start_probability, transition_probability, emission_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 4.24 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit viterbi(long_observations, states, start_probability, transition_probability, emission_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Since the computation takes quite a while for a long sequence (30000 steps), we should speed up the whole thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## A Cython implementation of the same algorithm\n",
    "\n",
    "The [`schimmel`](https://github.com/CPJKU/schimmel) package provides a Cython HMM implementation.\n",
    "\n",
    "In this implementation, the transitions and observations are decoupled as individual classes, the `TransitionModel` and the `ObservationModel`.\n",
    "\n",
    "The goal of both is to reduce the amount of information which needs to be stored or computed and the design of the Viterbi algorithm to be executed in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import schimmel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Create a TransitionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class HealthTransitionModel(schimmel.TransitionModel):\n",
    "    def __init__(self, literal_states, transition_probability):\n",
    "        # save the literal names of the states\n",
    "        self.literal_states = literal_states\n",
    "        # convert the dictionary with transitions to dense arrays\n",
    "        states = []\n",
    "        prev_states = []\n",
    "        probabilities = []\n",
    "        for from_state in transition_probability:\n",
    "            for to_state in transition_probability[from_state]:\n",
    "                states.append(self.literal_states.index(to_state))\n",
    "                prev_states.append(self.literal_states.index(from_state))\n",
    "                probabilities.append(transition_probability[from_state][to_state])\n",
    "        # make the lists sparse\n",
    "        sparse_arrays = self.make_sparse(states, prev_states, probabilities)\n",
    "        # instantiate a HealthTransitionModel\n",
    "        super(HealthTransitionModel, self).__init__(*sparse_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 4]\n",
      "[0 1 0 1]\n",
      "[ 0.7  0.4  0.3  0.6]\n",
      "[-0.35667494 -0.91629073 -1.2039728  -0.51082562]\n"
     ]
    }
   ],
   "source": [
    "htm = HealthTransitionModel(states, transition_probability)\n",
    "\n",
    "print htm.pointers\n",
    "print htm.states\n",
    "print htm.probabilities\n",
    "print htm.log_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This need's to be done only once and the transition model can be stored/pickled so there's no real need to optimise things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Create an Observation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HealthObservationModel(schimmel.ObservationModel):\n",
    "    def __init__(self, transition_model, literal_observations, emission_probability):\n",
    "        \"\"\"\n",
    "        Instantiate an ObservationModel.\n",
    "        \n",
    "        \"\"\"\n",
    "        # create the pointers array, saving the observation probability\n",
    "        # for 'Healthy' in the first column and 'Fever' in the second\n",
    "        self.pointers = np.arange(transition_model.num_states, dtype=np.uint32)\n",
    "        # save the literal names of the observations\n",
    "        self.literal_observations = literal_observations\n",
    "        # save the emmision probabilities in a suitable format\n",
    "        emission_probabilities = []\n",
    "        for state in emission_probability.keys():\n",
    "            probs = np.empty(len(emission_probability[state]))\n",
    "            for obs_state in emission_probability[state]:\n",
    "                obs_idx = self.literal_observations.index(obs_state)\n",
    "                tm_idx = transition_model.literal_states.index(state)\n",
    "                probs[obs_idx] = emission_probability[state][obs_state]\n",
    "            emission_probabilities.append(probs)\n",
    "        self.emission_probabilities = np.vstack(emission_probabilities).T\n",
    "        \n",
    "    def compute_log_densities_list(self, observations):\n",
    "        \"\"\"\n",
    "        Compute the log densities of the observations for each state.\n",
    "\n",
    "        :param observations: observations list\n",
    "        :return:             log densities [2D numpy array, np.float]\n",
    "        \n",
    "        \"\"\"\n",
    "        densities = np.empty((len(observations), len(self.pointers)))\n",
    "        for i, obs in enumerate(observations):\n",
    "            densities[i] = self.emission_probabilities[self.literal_observations.index(obs)]\n",
    "        return np.log(densities)\n",
    "    \n",
    "    def compute_log_densities(self, observations):\n",
    "        \"\"\"\n",
    "        Compute the log densities of the observations for each state.\n",
    "\n",
    "        :param observations: observations [numpy array]\n",
    "        :return:             log densities [2D numpy array, np.float]\n",
    "        \"\"\"\n",
    "        densities = np.empty((len(observations), len(self.pointers)))\n",
    "        densities[:] = self.emission_probabilities[observations]\n",
    "        return np.log(densities)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5  0.1]\n",
      " [ 0.4  0.3]\n",
      " [ 0.1  0.6]]\n",
      "[[-0.69314718 -2.30258509]\n",
      " [-0.91629073 -1.2039728 ]\n",
      " [-2.30258509 -0.51082562]]\n"
     ]
    }
   ],
   "source": [
    "hom = HealthObservationModel(htm, observations, emission_probability)\n",
    "print hom.emission_probabilities\n",
    "print hom.compute_log_densities_list(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's time the creation of the observation model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 23.5 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit hom.compute_log_densities_list(long_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Relatively fast, but if we use integer indices instead of literal observation values, cython does not need to call Python any more and thus is much faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1000 loops, best of 3: 995 µs per loop\n"
     ]
    }
   ],
   "source": [
    "observation_indices = np.empty(len(observations), dtype=np.int)\n",
    "for i, obs in enumerate(observations):\n",
    "    observation_indices[i] = observations.index(obs)\n",
    "long_observation_indices = np.tile(observation_indices, 10000)\n",
    "\n",
    "print np.allclose(hom.compute_log_densities_list(observations), hom.compute_log_densities(observation_indices))\n",
    "\n",
    "%timeit hom.compute_log_densities(long_observation_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Creation of the observation model takes a reasonable time, continue with the HMM and actually run the Viterbi algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Create a HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "hmm = schimmel.HMM(htm, hom, initial_distribution=np.asarray([0.6, 0.4]), num_threads=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Viterbi decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1], dtype=uint32), -3.437586228403492)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.viterbi(observation_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 4.23 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit hmm.viterbi(long_observation_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This is much faster (~4ms instead ~4s; speedup: ~1000x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Parallel Viterbi decoding\n",
    "\n",
    "Let's create a HMM model which uses 2 threads in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "parallel_hmm = schimmel.HMM(htm, hom, initial_distribution=np.asarray([0.6, 0.4]), num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 1.4 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit parallel_hmm.viterbi(long_observation_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Ups, using more threads is really killing the performance. We see that parallel decoding is not useful at all if we have only 2 states and compute the best previous state for them in parallel. Additionally, since each of these 2 states have only 2 transitions leading to them each, there is not much calculation needed to get the best predecessor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's design a more demanding scenario. Assume we have 1000 states with 1000 transitions each:\n",
    "\n",
    "### Create an appropriate transition model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools as it\n",
    "\n",
    "num_states = 1000\n",
    "\n",
    "# define state indices\n",
    "from_states = []\n",
    "to_states = []\n",
    "# define transitions\n",
    "for from_state, to_state in it.product(range(num_states), range(num_states)):\n",
    "    from_states.append(from_state)\n",
    "    to_states.append(to_state)\n",
    "# define a probability distribution\n",
    "density = np.random.uniform(low=0.0, high=1.0, size=num_states)\n",
    "density /= np.sum(density)\n",
    "# define transition probabilities\n",
    "transition_probabilities = np.tile(density, num_states)\n",
    "\n",
    "tm = schimmel.TransitionModel.from_dense(to_states, from_states, transition_probabilities)\n",
    "tm.num_transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an appropriate observation model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RandomObservationModel(schimmel.ObservationModel):\n",
    "    def compute_log_densities(self, observations):\n",
    "        \"\"\"\n",
    "        Return random observation desities.\n",
    " \n",
    "        :param observations: observations\n",
    "        :return:             log densities as a 2D numpy array with the number\n",
    "                             of rows being equal to the number of observations\n",
    "                             and the columns representing the different\n",
    "                             observation log probability densities. The type\n",
    "                             must be np.float.\n",
    "        \"\"\"\n",
    "        return np.random.rand(len(observations), len(self.pointers))\n",
    "\n",
    "om = RandomObservationModel(np.arange(tm.num_states, dtype=np.uint32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 17.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit om.compute_log_densities(np.zeros(2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create two HMMs, one for sequential decoding, one for parallel decoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_hmm = schimmel.HMM(tm, om, np.random.rand(num_states), num_threads=1)\n",
    "random_parallel_hmm = schimmel.HMM(tm, om, np.random.rand(num_states), num_threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 2.2 s per loop\n",
      "1 loops, best of 3: 1.7 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit random_hmm.viterbi(np.zeros(2000))\n",
    "%timeit random_parallel_hmm.viterbi(np.zeros(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
